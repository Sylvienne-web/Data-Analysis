{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "source": "import pandas as pd\nimport pyodbc, urllib, math\nfrom sqlalchemy import create_engine\nfrom sqlalchemy.types import NVARCHAR",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 1. Open csv file into defined dictionary"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": "file = r\"your_path\"\ndata_types = {'Date': 'object',\n 'Store Number': 'object',\n 'Store Name': 'object',\n 'City': 'object',\n 'Category Name': 'object',\n 'Vendor Number': 'object',\n 'Vendor Name': 'object'}\ndata = pd.read_csv(file, dtype=data_types)",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. Format datetime to SQL Server's standards"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%Y')\ndata['Date'] = data['Date'].dt.strftime('%Y-%m-%d')",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 3. Drop space in column names"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": "data.columns = data.columns.str.replace(' ', '_')",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 4. Save raw data after manipulating"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": "csv_file_dest = r\"C:\\your_dest_path\"\ndata.to_csv(csv_file_dest)",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 5. Set up SQL Server & specify location to load data"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": "sqlserver = urllib.parse.quote_plus(r\"Driver={ODBC Driver 17 for SQL Server};Server=your_server;Database=your_database;Trusted_Connection=Yes;\")\nengine = create_engine('mssql+pyodbc:///?odbc_connect={}'.format(sqlserver),fast_executemany=True)\ntablename='HMD_TABLE'\nschemaname = 'dbo'\ntxt_cols = data.select_dtypes(include = ['object']).columns\ncolumns = {col_name: NVARCHAR for col_name in txt_cols}",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 6. Load every 500,000 rows to SQL Server"
     ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": "start = 0\nend = math.ceil(len(data)/100000)*100000\nstep = 500000\nfor i in range(start,end,step):\n    data_sample = data.iloc[i:i+step,:]\n    data_sample.to_sql(tablename, schema=schemaname, con=engine, index=False, if_exists='append',dtype = columns)\n    print(f\"Rows {i}-{i+step} done\")",
      "metadata": {
        "trusted": true
      },
      "outputs": []
    }
  ]
}
